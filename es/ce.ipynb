{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djUvWu41mtXa"
      },
      "source": [
        "##### Copyright 2019 Los autores de TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "su2RaORHpReL"
      },
      "outputs": [

      ],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NztQK2uFpXT-"
      },
      "source": [
        "# Visualización de datos de imágenes en TensorBoard\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/tensorboard/image_summaries\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/image_summaries.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/tensorboard/blob/master/docs/image_summaries.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/tensorboard/docs/image_summaries.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar cuaderno</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDXRFe_qp5C3"
      },
      "source": [
        "## Visión general\n",
        "\n",
        "Con la **API de resumen de imágenes de TensorFlow,** puede registrar fácilmente tensores e imágenes arbitrarias y verlas en TensorBoard. Esto puede resultar extremadamente útil para muestrear y examinar los datos de entrada o para [visualizar los pesos de las capas](http://cs231n.github.io/understanding-cnn/) y los[tensores generados](https://hub.packtpub.com/generative-adversarial-networks-using-keras/) . También puede registrar datos de diagnóstico como imágenes que pueden ser útiles en el curso del desarrollo de su modelo.\n",
        "\n",
        "En este tutorial, aprenderá a utilizar la API de resumen de imágenes para visualizar tensores como imágenes. También aprenderá cómo tomar una imagen arbitraria, convertirla en un tensor y visualizarla en TensorBoard. Trabajará con un ejemplo simple pero real que utiliza resúmenes de imágenes para ayudarlo a comprender el rendimiento de su modelo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG-nnZK9qW9z"
      },
      "source": [
        "## Configuración"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3U5gdCw_nSG3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "# Load the TensorBoard notebook extension.\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1qIKtOBrqc9Y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version:  2.2\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "import io\n",
        "import itertools\n",
        "from packaging import version\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sklearn.metrics\n",
        "\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
        "    \"This notebook requires TensorFlow 2.0 or above.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq0gyXOGZ3-h"
      },
      "source": [
        "# Descargue el conjunto de datos Fashion-MNIST\n",
        "\n",
        "Vas a construir una red neuronal simple para clasificar imágenes en el conjunto de datos [Fashion-MNIST.](https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/) Este conjunto de datos consta de 70.000 imágenes en escala de grises de 28x28 de productos de moda de 10 categorías, con 7.000 imágenes por categoría.\n",
        "\n",
        "Primero, descargue los datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VmEQwCon3i7m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Download the data. The data is already divided into train and test.\n",
        "# The labels are integers representing classes.\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = \\\n",
        "    fashion_mnist.load_data()\n",
        "\n",
        "# Names of the integer classes, i.e., 0 -> T-short/top, 1 -> Trouser, etc.\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNsjMY0364j4"
      },
      "source": [
        "## Visualizando una sola imagen\n",
        "\n",
        "Para comprender cómo funciona la API de resumen de imágenes, ahora simplemente registrará la primera imagen de entrenamiento en su conjunto de entrenamiento en TensorBoard.\n",
        "\n",
        "Antes de hacer eso, examine la forma de sus datos de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FxMPcdmvBn9t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape:  (28, 28)\n",
            "Label:  9 -> Ankle boot\n"
          ]
        }
      ],
      "source": [
        "print(\"Shape: \", train_images[0].shape)\n",
        "print(\"Label: \", train_labels[0], \"->\", class_names[train_labels[0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F8zbUKfBuUt"
      },
      "source": [
        "Observe que la forma de cada imagen en el conjunto de datos es un tensor de forma de rango 2 (28, 28), que representa la altura y el ancho.\n",
        "\n",
        "Sin embargo, `tf.summary.image()` espera un tensor de rango 4 que contenga `(batch_size, height, width, channels)` . Por lo tanto, es necesario remodelar los tensores.\n",
        "\n",
        "Está registrando solo una imagen, por lo que `batch_size` es 1. Las imágenes son en escala de grises, así que configure los `channels` en 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yPh-7EWB8IK"
      },
      "outputs": [

      ],
      "source": [
        "# Reshape the image for the Summary API.\n",
        "img = np.reshape(train_images[0], (-1, 28, 28, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAdJDY3FCCwt"
      },
      "source": [
        "Ahora está listo para registrar esta imagen y verla en TensorBoard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJNpyVyxbVtT"
      },
      "outputs": [

      ],
      "source": [
        "# Clear out any prior log data.\n",
        "!rm -rf logs\n",
        "\n",
        "# Sets up a timestamped log directory.\n",
        "logdir = \"logs/train_data/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "# Creates a file writer for the log directory.\n",
        "file_writer = tf.summary.create_file_writer(logdir)\n",
        "\n",
        "# Using the file writer, log the reshaped image.\n",
        "with file_writer.as_default():\n",
        "  tf.summary.image(\"Training data\", img, step=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rngALbRogXe6"
      },
      "source": [
        "Ahora, use TensorBoard para examinar la imagen. Espere unos segundos a que la interfaz de usuario comience a funcionar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_X-wIy-lD9f"
      },
      "outputs": [

      ],
      "source": [
        "%tensorboard --logdir logs/train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8n8YqGlT3-c"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/tensorboard/blob/master/docs/images/images_single.png?raw=1\"/> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34enxJjjgWi7"
      },
      "source": [
        "La pestaña \"Imágenes\" muestra la imagen que acaba de iniciar sesión. Es una \"bota de tobillo\".\n",
        "\n",
        "La imagen se escala a un tamaño predeterminado para facilitar la visualización. Si desea ver la imagen original sin escala, marque \"Mostrar tamaño de imagen real\" en la esquina superior izquierda.\n",
        "\n",
        "Juega con los controles deslizantes de brillo y contraste para ver cómo afectan los píxeles de la imagen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjACE1lAsqUd"
      },
      "source": [
        "## Visualización de múltiples imágenes\n",
        "\n",
        "Registrar un tensor es genial, pero ¿y si quisiera registrar varios ejemplos de entrenamiento?\n",
        "\n",
        "Simplemente especifique la cantidad de imágenes que desea registrar al pasar datos a `tf.summary.image()` ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHUjCXbetIpb"
      },
      "outputs": [

      ],
      "source": [
        "with file_writer.as_default():\n",
        "  # Don't forget to reshape.\n",
        "  images = np.reshape(train_images[0:25], (-1, 28, 28, 1))\n",
        "  tf.summary.image(\"25 training data examples\", images, max_outputs=25, step=0)\n",
        "\n",
        "%tensorboard --logdir logs/train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr6LFQG9UD6z"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/tensorboard/blob/master/docs/images/images_multiple.png?raw=1\"/> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-7sZs3XuBBy"
      },
      "source": [
        "## Registro de datos de imágenes arbitrarios\n",
        "\n",
        "¿Qué pasa si desea visualizar una imagen que no es un tensor, como una imagen generada por [matplotlib](https://matplotlib.org/) ?\n",
        "\n",
        "Necesita un código repetitivo para convertir la trama en un tensor, pero después de eso, está listo para comenzar.\n",
        "\n",
        "En el siguiente código, registrará las primeras 25 imágenes como una buena cuadrícula usando la función subplot `subplot()` matplotlib. Luego verá la cuadrícula en TensorBoard:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5U_5WKt8bdQ"
      },
      "outputs": [

      ],
      "source": [
        "# Clear out prior logging data.\n",
        "!rm -rf logs/plots\n",
        "\n",
        "logdir = \"logs/plots/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "file_writer = tf.summary.create_file_writer(logdir)\n",
        "\n",
        "def plot_to_image(figure):\n",
        "  \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
        "  returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
        "  # Save the plot to a PNG in memory.\n",
        "  buf = io.BytesIO()\n",
        "  plt.savefig(buf, format='png')\n",
        "  # Closing the figure prevents it from being displayed directly inside\n",
        "  # the notebook.\n",
        "  plt.close(figure)\n",
        "  buf.seek(0)\n",
        "  # Convert PNG buffer to TF image\n",
        "  image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
        "  # Add the batch dimension\n",
        "  image = tf.expand_dims(image, 0)\n",
        "  return image\n",
        "\n",
        "def image_grid():\n",
        "  \"\"\"Return a 5x5 grid of the MNIST images as a matplotlib figure.\"\"\"\n",
        "  # Create a figure to contain the plot.\n",
        "  figure = plt.figure(figsize=(10,10))\n",
        "  for i in range(25):\n",
        "    # Start next subplot.\n",
        "    plt.subplot(5, 5, i + 1, title=class_names[train_labels[i]])\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "  \n",
        "  return figure\n",
        "\n",
        "# Prepare the plot\n",
        "figure = image_grid()\n",
        "# Convert to image and log\n",
        "with file_writer.as_default():\n",
        "  tf.summary.image(\"Training data\", plot_to_image(figure), step=0)\n",
        "\n",
        "%tensorboard --logdir logs/plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_tIghRsXY7S"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/tensorboard/blob/master/docs/images/images_arbitrary.png?raw=1\"/> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZx70BC1zhgW"
      },
      "source": [
        "## Construyendo un clasificador de imágenes\n",
        "\n",
        "Ahora pon todo esto junto con un ejemplo real. Después de todo, estás aquí para hacer aprendizaje automático y no para trazar imágenes bonitas.\n",
        "\n",
        "Utilizará resúmenes de imágenes para comprender qué tan bien le está yendo a su modelo mientras entrena un clasificador simple para el conjunto de datos Fashion-MNIST.\n",
        "\n",
        "Primero, cree un modelo muy simple y compílelo, configurando el optimizador y la función de pérdida. El paso de compilación también especifica que desea registrar la precisión del clasificador a lo largo del camino."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R74hPWJHzgvZ"
      },
      "outputs": [

      ],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', \n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdT_PpZB1UMn"
      },
      "source": [
        "Al entrenar un clasificador, es útil ver la [matriz de confusión](https://en.wikipedia.org/wiki/Confusion_matrix) . La matriz de confusión le brinda un conocimiento detallado de cómo se está desempeñando su clasificador en los datos de prueba.\n",
        "\n",
        "Defina una función que calcule la matriz de confusión. Utilizará una función conveniente de [Scikit-learn](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html) para hacer esto, y luego lo trazará usando matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBiXP8-UO8t6"
      },
      "outputs": [

      ],
      "source": [
        "def plot_confusion_matrix(cm, class_names):\n",
        "  \"\"\"\n",
        "  Returns a matplotlib figure containing the plotted confusion matrix.\n",
        "\n",
        "  Args:\n",
        "    cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
        "    class_names (array, shape = [n]): String names of the integer classes\n",
        "  \"\"\"\n",
        "  figure = plt.figure(figsize=(8, 8))\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "  plt.title(\"Confusion matrix\")\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(class_names))\n",
        "  plt.xticks(tick_marks, class_names, rotation=45)\n",
        "  plt.yticks(tick_marks, class_names)\n",
        "\n",
        "  # Compute the labels from the normalized confusion matrix.\n",
        "  labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "\n",
        "  # Use white text if squares are dark; otherwise black.\n",
        "  threshold = cm.max() / 2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    color = \"white\" if cm[i, j] > threshold else \"black\"\n",
        "    plt.text(j, i, labels[i, j], horizontalalignment=\"center\", color=color)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  return figure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lOAl_v26QGq"
      },
      "source": [
        "Ahora está listo para entrenar al clasificador y registrar regularmente la matriz de confusión a lo largo del camino.\n",
        "\n",
        "Esto es lo que harás:\n",
        "\n",
        "1. Cree la [devolución de llamada de Keras TensorBoard](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard) para registrar métricas básicas\n",
        "2. Cree un [Keras LambdaCallback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LambdaCallback) para registrar la matriz de confusión al final de cada época\n",
        "3. Entrene el modelo usando Model.fit (), asegurándose de pasar ambas devoluciones de llamada\n",
        "\n",
        "A medida que avanza el entrenamiento, desplácese hacia abajo para ver cómo se inicia TensorBoard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utd-vH6hn5RY"
      },
      "outputs": [

      ],
      "source": [
        "# Clear out prior logging data.\n",
        "!rm -rf logs/image\n",
        "\n",
        "logdir = \"logs/image/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "# Define the basic TensorBoard callback.\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXQ7-9CF0TPA"
      },
      "outputs": [

      ],
      "source": [
        "def log_confusion_matrix(epoch, logs):\n",
        "  # Use the model to predict the values from the validation dataset.\n",
        "  test_pred_raw = model.predict(test_images)\n",
        "  test_pred = np.argmax(test_pred_raw, axis=1)\n",
        "\n",
        "  # Calculate the confusion matrix.\n",
        "  cm = sklearn.metrics.confusion_matrix(test_labels, test_pred)\n",
        "  # Log the confusion matrix as an image summary.\n",
        "  figure = plot_confusion_matrix(cm, class_names=class_names)\n",
        "  cm_image = plot_to_image(figure)\n",
        "\n",
        "  # Log the confusion matrix as an image summary.\n",
        "  with file_writer_cm.as_default():\n",
        "    tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
        "\n",
        "# Define the per-epoch callback.\n",
        "cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6CV7dy-oJZu"
      },
      "outputs": [

      ],
      "source": [
        "# Start TensorBoard.\n",
        "%tensorboard --logdir logs/image\n",
        "\n",
        "# Train the classifier.\n",
        "model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    epochs=5,\n",
        "    verbose=0, # Suppress chatty output\n",
        "    callbacks=[tensorboard_callback, cm_callback],\n",
        "    validation_data=(test_images, test_labels),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7PnxGf8Ur6F"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/tensorboard/blob/master/docs/images/images_accuracy.png?raw=1\"/> -->\n",
        "\n",
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/tensorboard/blob/master/docs/images/images_cm.png?raw=1\"/> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6URWgszz9Jut"
      },
      "source": [
        "Tenga en cuenta que la precisión aumenta tanto en el tren como en los conjuntos de validación. Buena seńal. Pero, ¿cómo se está desempeñando el modelo en subconjuntos específicos de datos?\n",
        "\n",
        "Seleccione la pestaña \"Imágenes\" para visualizar sus matrices de confusión registradas. Marque \"Mostrar tamaño de imagen real\" en la parte superior izquierda para ver la matriz de confusión a tamaño completo.\n",
        "\n",
        "De forma predeterminada, el panel muestra el resumen de la imagen del último paso o época registrada. Utilice el control deslizante para ver matrices de confusión anteriores. Observe cómo la matriz cambia significativamente a medida que avanza el entrenamiento, los cuadrados más oscuros se fusionan a lo largo de la diagonal y el resto de la matriz tiende hacia el 0 y el blanco. ¡Esto significa que su clasificador está mejorando a medida que avanza el entrenamiento! ¡Buen trabajo!\n",
        "\n",
        "La matriz de confusión muestra que este modelo simple tiene algunos problemas. A pesar del gran progreso, las camisas, camisetas y suéteres se están confundiendo entre sí. El modelo necesita más trabajo.\n",
        "\n",
        "Si está interesado, intente mejorar este modelo con una [red convolucional](https://medium.com/tensorflow/hello-deep-learning-fashion-mnist-with-keras-50fcff8cd74a) (CNN)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [

      ],
      "name": "image_summaries.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
